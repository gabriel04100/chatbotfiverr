{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json','r') as file:\n",
    "    data=json.load(file)\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "X_train=[]\n",
    "y_train =[]\n",
    "tags=[]\n",
    "\n",
    "for item in data['intents']:\n",
    "    if item['tag'] not in tags:\n",
    "            tags.append(item['tag'])\n",
    "\n",
    "for item in data['intents']:\n",
    "    for  X in item['patterns']:\n",
    "        X = word_tokenize(X)\n",
    "        X=[stemmer.stem(item) for item in X]\n",
    "        X = ' '.join(X)\n",
    "        X_train.append(X)\n",
    "        y_train.append(item['tag'])\n",
    "        \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized= vectorizer.fit_transform(X_train)\n",
    "X_train_vectorized.toarray()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(tags)\n",
    "tags_labelled=le.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(i):\n",
    "    stemmer=PorterStemmer()\n",
    "    result=word_tokenize(i)\n",
    "    result=[stemmer.stem(item) for item in result]\n",
    "    result = ' '.join(result)\n",
    "    return [result]\n",
    "\n",
    "\n",
    "model_pipeline= make_pipeline(TfidfVectorizer(),MLPClassifier(max_iter=3000))\n",
    "model_pipeline.fit(X_train,tags_labelled)\n",
    "\n",
    "test=le.inverse_transform(model_pipeline.predict(preprocess('hey')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data['intents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have a good day'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(df[df['tag']==test[0]].responses.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's 4 department of languages : mathematics, chemistry, biology, physics\""
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['responses'][5][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "330a25604446c81fa0236edaa6156392a8b857f97356567c0ea50a692814b20f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
